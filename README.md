

# Master's Thesis: Enhancing Text Classification with LLM-Augmented BertGCN and Advanced Machine Learning Techniques



## Overview

This work employs advanced machine learning techniques to improve text processing and representation. Quantization enhances computational efficiency while maintaining accuracy. Input data is vectorized and expanded using Llama 3 to address data scarcity and boost robustness. Heterogeneous graph structures are constructed from textual data, while the BERTGCN model generates semantically rich textual graphs using BERT word vectors. These graphs serve as inputs to graph neural networks, enhancing text classification and other NLP tasks. Experimental results highlight the approach's effectiveness in achieving superior text representation and processing capabilities.



## Acknowledgments

This project is inspired by the BertGCN and TextGCN. Many thanks to the authors of the original paper for their foundational contributions. For further details, please refer to their work:  


[[2105.05727] BertGCN: Transductive Text Classification by Combining GCN and BERT](https://arxiv.org/abs/2105.05727)

[[1809.05679] Graph Convolutional Networks for Text Classification](https://arxiv.org/abs/1809.05679)


